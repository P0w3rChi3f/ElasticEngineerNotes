# FileBeat

## Install Filebeat
`yum install filebeat`  
`cd /etc/filebeat/`  

## Configure Filebeat
`vi filebeat.yml`  

```
 24   enabled: true
 28     - /data/suricata/eve.json  
 29     - /data/fsf/logs/rockout.log

 json.keys_under_root
```
Delete everythind under ====FileBeat Inputs==== and replace with the following config  
```
filebeat.inputs:
  - type: log
    paths:
      - /data/suricata/eve.json
    json.keys_under_root: true
    fields:
      kafka_topic: suricata-raw
    fields_under_root: true
  - type: log
    paths:
      - /data/fsf/logs/rockout.log
    json.keys_under_root: true
    fields:
      kafka_topic: fsf-raw
    fields_under_root: true
processors:
  - decode_json_fields:
      fields:
        - message
        - Scan Time
        - Filename
        - objects
        - Source
        - meta
        - Alert
        - Summary
    process_array: true
    max_depth: 10
 ```

 comment out 
 `Elasticsearch Output`

 Add kafka Output
 ```
 output.kafka:
  hosts: ["172.16.90.100:9092"]
  topic: '%{[kafka_topic]}'

 ```

 Filebeat uses prospectors to crawl to a path and fetch files (think gold or mineral propector). The prospector options sections in the yml config file is listed under `filebeat.prospectors`. Each prospector is delineated by a dash (-)

 The `fields` option will also be utilized so that add additionsl information to the output. In this case, we will add the `kafka_topic` to our output and set the `fields_under_root` option to true so the new field is stored at the top leve othe outpu docuren. If not set the `fields` option would 

 Can add fields to data at (Not needed for class)
 ```
 46   fields:
 ```

 ## Troubleshooting
 ```
 yum install yamllint

/usr/share/kafka/bin/kafka-topics.sh --list --bootstrap-server 172.16.90.100:9092
 ```

 look for fsf and suricat topics at 
 /data/kafka
 firewall-cmd --list-ports
 ss -lnt
